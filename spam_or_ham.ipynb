{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     v1                                                 v2\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "# In this kernel, we gonna build up a tool to classify the SMS messages into 2 categories: spam or ham!!!\n",
    "# We're gonna use the Naive Bayesian classifier first, and try to apply the alternatives later.\n",
    "\n",
    "# Firstly, we import the data using 'pandas', 'numpy', and 'nltk.corpus' packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords as sw\n",
    "\n",
    "data = pd.read_csv('spam.csv', encoding='latin-1')\n",
    "\n",
    "# Since the 3 last column of the data set is empty, we will drop them off\n",
    "data = data.iloc[:,:2]\n",
    "\n",
    "# Check the shape of the data\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     v1                                                 v2\n",
      "0   ham  go jurong point crazy available bugis n great ...\n",
      "1   ham                            ok lar joking wif u oni\n",
      "2  spam  free entry 2 wkly comp win fa cup final tkts 2...\n",
      "3   ham                u dun say early hor u c already say\n",
      "4   ham        nah dont think goes usf lives around though\n"
     ]
    }
   ],
   "source": [
    "# We will do some pre-analysing process, like eliminating the stopwords, eliminating the punctuation, etc.\n",
    "# Firstly, we need to transform all of the words in every messages to the lower case form. This action helps to avoid the same words\n",
    "# appearing many times, e.g. 'Analysis', 'analysis', 'analYsis', etc.\n",
    "data['v2'] = data['v2'].apply(lambda x: ' '.join(i.lower() for i in x.split()))\n",
    "\n",
    "# Next, remove the punctuation\n",
    "data['v2'] = data['v2'].str.replace('[^\\w\\s]', '')\n",
    "\n",
    "# Lastly, we remove stopwords in each message. To do that, create a list of stop words, which is available in the 'stopwords' package\n",
    "stop = sw.words('english')\n",
    "data['v2'] = data['v2'].apply(lambda x: ' '.join(i for i in x.split() if i not in stop))\n",
    "\n",
    "# So, stop is a list containing stop words in english\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     v1                                                 v2\n",
      "0   ham  go jurong point crazy available bugis n great ...\n",
      "1   ham                            ok lar joking wif u oni\n",
      "2  spam  free entry 2 wkly comp win fa cup final tkts 2...\n",
      "3   ham                u dun say early hor u c already say\n",
      "4   ham        nah dont think goes usf lives around though\n"
     ]
    }
   ],
   "source": [
    "# Since we have totally 5572 messages, the training set will include around 80% of the data set, which is 4457 messages.\n",
    "train = data.iloc[:4458]\n",
    "test = data.iloc[4458:]\n",
    "print(train.head())\n",
    "\n",
    "# Then, we compute the number of ham and spam SMS correspondingly\n",
    "ham = train.loc[:,'v1'][train.loc[:,'v1'] == 'ham'].count()\n",
    "spam = train.loc[:,'v1'][train.loc[:,'v1'] == 'spam'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     v1                                                 v2  count_word\n",
      "0   ham  go jurong point crazy available bugis n great ...          16\n",
      "1   ham                            ok lar joking wif u oni           6\n",
      "2  spam  free entry 2 wkly comp win fa cup final tkts 2...          23\n",
      "3   ham                u dun say early hor u c already say           9\n",
      "4   ham        nah dont think goes usf lives around though           8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "# First analysis, count the number of words in each message\n",
    "train.loc[:,'count_word'] = train.loc[:,'v2'].apply(lambda x: len(str(x).split(\" \")))\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     v1                                                 v2  count_word  \\\n",
      "0   ham  go jurong point crazy available bugis n great ...          16   \n",
      "1   ham                            ok lar joking wif u oni           6   \n",
      "2  spam  free entry 2 wkly comp win fa cup final tkts 2...          23   \n",
      "3   ham                u dun say early hor u c already say           9   \n",
      "4   ham        nah dont think goes usf lives around though           8   \n",
      "\n",
      "   count_char  \n",
      "0          82  \n",
      "1          23  \n",
      "2         135  \n",
      "3          35  \n",
      "4          43  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "# Then, we count the number of characters\n",
    "train.loc[:,'count_char'] = train.loc[:,'v2'].apply(lambda x: len(x))\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our target is extracting words in messages and count the frequency of these words appearing in spam and ham SMS.\n",
    "dic_words_ham = {}\n",
    "dic_words_spam = {}\n",
    "\n",
    "# Idea is to loop over rows of the training set, each row is a single message, and we just add the words to the dictionary\n",
    "for index, i in train.iterrows():\n",
    "    # To do it, split each word in the message\n",
    "    sep_words = i['v2'].split(\" \")\n",
    "    for j in sep_words:\n",
    "        if i['v1'] == 'ham':\n",
    "            if j in dic_words_ham:\n",
    "                dic_words_ham[j] += 1\n",
    "            else:\n",
    "                dic_words_ham[j] = 1\n",
    "        else:\n",
    "            if j in dic_words_spam:\n",
    "                dic_words_spam[j] += 1\n",
    "            else:\n",
    "                dic_words_spam[j] = 1\n",
    "\n",
    "# Now, we have two dictionaries, one contains the words in spam SMS and the other consists of words in ham SMS.\n",
    "# Then, we try to combine 2 dictionaries into a sole table. Firstly, we try to create a list of words in both types of SMS\n",
    "words = list(dic_words_ham.keys());\n",
    "for i in dic_words_spam.keys():\n",
    "    if i not in words:\n",
    "        words.append(i)\n",
    "        \n",
    "# Next, we count the frequency of each word in both spam and ham SMS, returna data frame.\n",
    "spam_freq = []\n",
    "ham_freq = []\n",
    "\n",
    "for i in words:\n",
    "    if i in dic_words_spam.keys():\n",
    "        spam_freq.append(dic_words_spam[i])\n",
    "    else:\n",
    "        spam_freq.append(0)\n",
    "\n",
    "for i in words:\n",
    "    if i in dic_words_ham.keys():\n",
    "        ham_freq.append(dic_words_ham[i])\n",
    "    else:\n",
    "        ham_freq.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               words  spam_freq  ham_freq  total_freq\n",
      "0                 go         25       193         218\n",
      "1             jurong          0         1           1\n",
      "2              point          0        11          11\n",
      "3              crazy          3         8          11\n",
      "4          available          3        12          15\n",
      "5              bugis          0         6           6\n",
      "6                  n          6       112         118\n",
      "7              great          6        79          85\n",
      "8              world          1        26          27\n",
      "9                 la          0         5           5\n",
      "10                 e          6        63          69\n",
      "11            buffet          0         2           2\n",
      "12              cine          0         7           7\n",
      "13               got          3       189         192\n",
      "14             amore          0         1           1\n",
      "15               wat          0        76          76\n",
      "16                ok          5       227         232\n",
      "17               lar          0        33          33\n",
      "18            joking          0         2           2\n",
      "19               wif          0        19          19\n",
      "20                 u        125       773         898\n",
      "21               oni          0         3           3\n",
      "22               dun          0        43          43\n",
      "23               say          0        80          80\n",
      "24             early          0        30          30\n",
      "25               hor          0         1           1\n",
      "26                 c         15        52          67\n",
      "27           already          1        73          74\n",
      "28               nah          0        10          10\n",
      "29              dont         20       216         236\n",
      "...              ...        ...       ...         ...\n",
      "8321      messagesim          1         0           1\n",
      "8322         theredo          1         0           1\n",
      "8323           abuse          1         0           1\n",
      "8324     09061744553          1         0           1\n",
      "8325           polyh          1         0           1\n",
      "8326     0789xxxxxxx          1         0           1\n",
      "8327     09058091870          1         0           1\n",
      "8328            å600          1         0           1\n",
      "8329        landmark          1         0           1\n",
      "8330             bob          1         0           1\n",
      "8331           barry          1         0           1\n",
      "8332           83738          1         0           1\n",
      "8333          tonexs          1         0           1\n",
      "8334         renewed          1         0           1\n",
      "8335  wwwclubzedcouk          1         0           1\n",
      "8336         billing          1         0           1\n",
      "8337        wwwtcbiz          1         0           1\n",
      "8338            polo          1         0           1\n",
      "8339             373          1         0           1\n",
      "8340             w1j          1         0           1\n",
      "8341             6hl          1         0           1\n",
      "8342      8000930705          1         0           1\n",
      "8343           recpt          1         0           1\n",
      "8344              13          1         0           1\n",
      "8345     subscribers          1         0           1\n",
      "8346              gb          1         0           1\n",
      "8347         headset          1         0           1\n",
      "8348             adp          1         0           1\n",
      "8349          floppy          1         0           1\n",
      "8350          snappy          1         0           1\n",
      "\n",
      "[8351 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# From a data frame by three columns 'words', 'spam_freq' and 'ham_freq'. First, create a dictionary\n",
    "dic_freq_words = {'words': words, 'spam_freq': spam_freq, 'ham_freq': ham_freq}\n",
    "freq_words = pd.DataFrame.from_dict(dic_freq_words)\n",
    "\n",
    "# We want to have one more column that is the total frequency of these words, in both spam and ham SMS\n",
    "freq_words.loc[:,'total_freq'] = freq_words.loc[:,'spam_freq'] + freq_words.loc[:,'ham_freq']\n",
    "\n",
    "print(freq_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After all materials are prepared, we execute the Naive Bayesian classifier to classify the SMS\n",
    "# We will compute the posterior probability of ham and spam SMS. To be more concrete, we will compute P(ham|data) and P(spam|data)\n",
    "\n",
    "# The priors P(ham) and P(spam). These probabilities are straight-forward, since they are just the proportion of ham and spam SMS\n",
    "prior_ham = ham/(ham+spam)\n",
    "prior_spam = spam/(ham+spam)\n",
    "\n",
    "# Compute the likelihoods P(bodytext|ham) and p(bodytext|spam).\n",
    "# Firstly, number of words in ham and spam category\n",
    "count_word_ham = 0\n",
    "count_word_spam = 0\n",
    "\n",
    "for index, i in enumerate(freq_words.loc[:,'words']):\n",
    "    if freq_words.loc[index,'ham_freq'] != 0:\n",
    "        count_word_ham += 1\n",
    "    elif freq_words.loc[index,'spam_freq'] != 0:\n",
    "        count_word_spam += 1\n",
    "\n",
    "# The likelihood P(bodytext|ham) = PRODUCT(P(each_word|ham)). However, there are some words that appear in spam SMS, \n",
    "# but not in ham SMS, then P(that_word) = 0. This will make PRODUCT(P(each_word|ham)) = 0. To solve it, we compute P(each_word|ham)\n",
    "# as (frequency of that word in ham + 1)/(total words in ham + number of distinct words in both categories)\n",
    "\n",
    "# Number of distinct words: we can easily count them by looking at the 'total_freq' column\n",
    "count_dist_words = freq_words.loc[:,'total_freq'][freq_words.loc[:,'total_freq'] == 1].count()\n",
    "\n",
    "# Now, we come back to the original data set to compute the likelihood of each SMS. We have to notice one more thing before computing\n",
    "# Since we have so many words, and the frequency of a single word is negilible compared to the number of all words, the P(each_word|ham)\n",
    "# or P(each_word|spam) is prohibitive close to 0, and when the products are taken over each SMS, they could return 0 for long messages.\n",
    "\n",
    "# To solve this problem, we take logarithm for all probabilities.\n",
    "posteriors_ham = []\n",
    "posteriors_spam = []\n",
    "\n",
    "for i in list(train.loc[:,'v2']):\n",
    "    aa = str(i).split(' ')\n",
    "    bb = set(aa)\n",
    "    freq_word_ham = []\n",
    "    freq_word_spam = []\n",
    "    for j in bb:\n",
    "        index_j = list(freq_words.loc[:,'words']).index(j)\n",
    "        freq_word_ham.append(np.log((freq_words.loc[index_j, 'ham_freq'] + 1)/(count_word_ham + count_dist_words)))\n",
    "        freq_word_spam.append(np.log((freq_words.loc[index_j, 'spam_freq'] + 1)/(count_word_spam + count_dist_words)))\n",
    "    ham = sum(freq_word_ham) + np.log(prior_ham)\n",
    "    spam = sum(freq_word_spam) + np.log(prior_spam)\n",
    "    posteriors_ham.append(ham)\n",
    "    posteriors_spam.append(spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Now, stick these two columns into the original data set (just for the easy observation)\n",
    "train.loc[:,'post_ham'] = posteriors_ham\n",
    "train.loc[:,'post_spam'] = posteriors_spam\n",
    "\n",
    "# It is the last step when we will decide whether a message is spam or ham by compare there posteriors in ham and spam categories\n",
    "# If posterior_ham > posterior_spam, that message is classified as ham and vice versa.\n",
    "prediction = []\n",
    "for index, i in enumerate(train.loc[:,'post_ham']):\n",
    "    if i > train.loc[index,'post_spam']:\n",
    "        prediction.append('ham')\n",
    "    else:\n",
    "        prediction.append('spam')\n",
    "\n",
    "train['prediction'] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.993943472409152\n"
     ]
    }
   ],
   "source": [
    "# Assess the classifier\n",
    "# 1. Using the training set\n",
    "precision = sum(train.loc[:,'v1'] == train.loc[:,'prediction'])/len(train.loc[:,'prediction'])\n",
    "print(precision)\n",
    "\n",
    "# It is 99.39% correct, impressive performance of Naive Bayesian classifier!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
